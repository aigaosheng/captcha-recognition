{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "016f5dc8-8f25-4fc6-b0ef-066838ffa4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Start training using 22 samples\n",
      "*** model saved to ./model/captcha_lr.pkl\n",
      "*** train done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gs/miniconda3/envs/t2v/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Solution 1: use traditional machine learning model\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "import random\n",
    "\n",
    "#define captcha class for train, predict\n",
    "class Captcha(object):\n",
    "    def __init__(self, is_train = False, model_pth = None):\n",
    "        #function mode control and moel saved path\n",
    "        self.model_pth = model_pth\n",
    "        self.model = None\n",
    "\n",
    "        if not is_train:\n",
    "            try:\n",
    "                with open(self.model_pth, \"rb\") as ofl:\n",
    "                    self.model = pickle.load(ofl)\n",
    "                    print(f\"*** model loading success -> {self.model_pth}\")\n",
    "            except:\n",
    "                raise Exception(f\" *** model not found -> {self.model_pth}\")\n",
    "                \n",
    "    def fit(self, train_sample, train_label):\n",
    "        print(f\"***** Start training using {len(train_label)} samples\")\n",
    "        self.model = LogisticRegression(penalty = \"l1\", solver = \"saga\", random_state = 20240116)\n",
    "        self.model.fit(train_sample, train_label)\n",
    "        if self.model_pth:\n",
    "            with open(self.model_pth, \"wb\") as ofl:\n",
    "                pickle.dump(self.model, ofl)\n",
    "                print(f\"*** model saved to {self.model_pth}\")\n",
    "        print(f\"*** train done\")\n",
    "\n",
    "    def __call__(self, im_path, save_path):\n",
    "        \"\"\"\n",
    "        Algo for inference\n",
    "        args:\n",
    "            im_path: image file to load and to infer, \n",
    "                \n",
    "            save_path: output file path to save the one-line outcome\n",
    "        \"\"\"\n",
    "        if im_path.endswith(\".txt\"):\n",
    "            #load text format image data same sample\n",
    "            input_data, _ = load_captchas_image_label(im_path)\n",
    "        else:\n",
    "            #load image data\n",
    "            img = cv2.imread(im_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            input_data = img.mean(axis = 2).reshape(-1,)\n",
    "            \n",
    "        pred = self.model.predict([input_data])[0]\n",
    "\n",
    "        if save_path:\n",
    "            nm = im_path.split(\"/\")[-1].split(\".\")[0] + \".txt\"\n",
    "            o_file = os.path.join(save_path, nm)\n",
    "            with open(o_file, \"wt\") as ofl:\n",
    "                ofl.write(pred)\n",
    "\n",
    "        return pred\n",
    "        \n",
    "\n",
    "def load_captchas_image_label(filename_input, filename_input_label = None):\n",
    "    #load samples\n",
    "    pixels = []\n",
    "    with open(filename_input, \"r\") as f:\n",
    "        next(f)\n",
    "        for line in f:\n",
    "            for item in line.split(\" \"):\n",
    "                vals = [int(val) for val in item.split(\",\")]\n",
    "                pixels.append(sum(vals)/len(vals))\n",
    "    #\n",
    "    label = None\n",
    "    if filename_input_label:\n",
    "        with open(filename_input_label, \"r\") as f:\n",
    "            label = f.read().strip()\n",
    "    \n",
    "    return pixels, label\n",
    "        \n",
    "# Step-1: Prepare data for model training & test\n",
    "captcha_image_folder = \"./input\"\n",
    "captcha_image_label_folder = \"./output\"\n",
    "# inputs = []\n",
    "# labels = []\n",
    "x_train, x_test, y_train, y_test, id_train, id_test = [], [], [], [], [], []\n",
    "ratio_train = 0.8\n",
    "\n",
    "random.seed(20240116)\n",
    "for filename in os.listdir(captcha_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        input_image_fl = os.path.join(captcha_folder, filename)\n",
    "        input_image_label_fl = os.path.join(captcha_image_label_folder, \"output\" + filename.split('input')[1])\n",
    "        isample = load_captchas_image_label(input_image_fl, input_image_label_fl)\n",
    "        \n",
    "        if random.random() <= ratio_train:   \n",
    "            x_train.append(isample[0])\n",
    "            y_train.append(isample[1])\n",
    "            id_train.append(filename)\n",
    "        else:\n",
    "            x_test.append(isample[0])\n",
    "            y_test.append(isample[1])\n",
    "            id_test.append(filename)\n",
    "            \n",
    "# Split the data into training and testing sets\n",
    "# x_train, x_test, y_train, y_test = train_test_split(inputs, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#Step-2:\n",
    "inst_learner = Captcha(is_train = True, model_pth = \"./model/captcha_lr.pkl\")\n",
    "inst_learner.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1e6d628d-13a3-453f-a8b1-fc2c3d2d13f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input10.txt', 'input22.txt', 'input23.txt']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d69f6a84-3b6d-4bc1-826f-f4c07345deed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** model loading success -> ./model/captcha_lr.pkl\n",
      "./input/input10.txt\n",
      "./input/input22.txt\n",
      "./input/input23.txt\n"
     ]
    }
   ],
   "source": [
    "inst_learner = Captcha(is_train = False, model_pth = \"./model/captcha_lr.pkl\")\n",
    "\n",
    "#test inference using text\n",
    "for v in id_test:\n",
    "    name = os.path.join(captcha_image_folder, v) \n",
    "    print(name)\n",
    "    inst_learner(name, \"./output_lr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "38d8619d-d22e-4291-9900-267450136bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-large-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "/home/gs/miniconda3/envs/t2v/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./input/input10.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gs/miniconda3/envs/t2v/lib/python3.10/site-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output_i2t/input10.txt\n",
      "./input/input22.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gs/miniconda3/envs/t2v/lib/python3.10/site-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output_i2t/input22.txt\n",
      "./input/input23.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gs/miniconda3/envs/t2v/lib/python3.10/site-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output_i2t/input23.txt\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Solution 2: use SOTA Image-to-Text pretrained model\n",
    "\"\"\"\n",
    "\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "\n",
    "class CaptchaI2T(object):\n",
    "    def __init__(self, ):\n",
    "        self.pipe = pipeline(\"image-to-text\", model=\"microsoft/trocr-large-printed\")\n",
    "\n",
    "    def __call__(self, im_path, save_path):\n",
    "        \"\"\"\n",
    "        Algo for inference\n",
    "        args:\n",
    "            im_path: image file to load and to infer, \n",
    "                \n",
    "            save_path: output file path to save the one-line outcome\n",
    "        \"\"\"\n",
    "        try:\n",
    "            input_data = Image.open(im_path).convert(\"RGB\")\n",
    "            input_data.show()\n",
    "            pred2 = self.pipe(input_data)[0]\n",
    "            pred = pred2[\"generated_text\"]\n",
    "            # print(pred)\n",
    "            \n",
    "            if save_path:\n",
    "                nm = im_path.split(\"/\")[-1].split(\".\")[0] + \".txt\"\n",
    "                o_file = os.path.join(save_path, nm)\n",
    "                print(o_file)\n",
    "                with open(o_file, \"wt\") as ofl:\n",
    "                    ofl.write(pred)\n",
    "        except:\n",
    "            print(f\"*** Inference failed -> {im_path}\")\n",
    "            pred = None\n",
    "\n",
    "        return pred\n",
    "\n",
    "#test\n",
    "inst_i2t = CaptchaI2T()\n",
    "\n",
    "#test inference using text\n",
    "for v in id_test:\n",
    "    name = os.path.join(captcha_image_folder, v.split(\".\")[0] + \".jpg\") \n",
    "    print(name)\n",
    "    inst_i2t(name, \"./output_i2t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "868b25a8-8585-4b3f-9348-02db7bda8930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.utils import make_image_grid\n",
    "img_lst = []\n",
    "pred_lr = []\n",
    "pred_i2t = []\n",
    "label = []\n",
    "\n",
    "for v in id_test:\n",
    "    name = os.path.join(\"./input\", v.split(\".\")[0] + \".jpg\") \n",
    "    img_lst.append(Image.open(name))\n",
    "    name = os.path.join(\"./output\", \"output\"+v.split(\"input\")[1])\n",
    "    with open(name, \"rt\") as ofl:\n",
    "        s = ofl.read().strip(\"\\n\")\n",
    "        label.append(s)\n",
    "\n",
    "    name = os.path.join(\"./output\", \"output\"+v.split(\"input\")[1])\n",
    "    with open(name, \"rt\") as ofl:\n",
    "        s = ofl.read().strip(\"\\n\")\n",
    "        label.append(s)\n",
    "\n",
    "    name = os.path.join(\"./output_lr\", \"input\"+v.split(\"input\")[1])\n",
    "    with open(name, \"rt\") as ofl:\n",
    "        s = ofl.read().strip(\"\\n\")\n",
    "        pred_lr.append(s)\n",
    "\n",
    "    name = os.path.join(\"./output_i2t\", \"input\"+v.split(\"input\")[1])\n",
    "    with open(name, \"rt\") as ofl:\n",
    "        s = ofl.read().strip(\"\\n\")\n",
    "        pred_i2t.append(s)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8d19629b-0de0-48e2-b696-a4285fe20a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=180x30>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Input image\")\n",
    "make_image_grid(img_lst, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6f56e758-af46-4852-88b3-108fb23e7a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: Logistic regression\n",
      "['ZRMQU', '6O5W1', 'WGST7']\n",
      "Model prediction: image-to-text\n",
      "['GZMBA', 'HCE91', 'WELXV']\n"
     ]
    }
   ],
   "source": [
    "print(\"Model prediction: Logistic regression\")\n",
    "print(pred_lr)\n",
    "\n",
    "print(\"Model prediction: image-to-text\")\n",
    "print(pred_i2t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d118819-533b-4dac-a66e-73306cf2b69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "From above 3 samples, image-to-text is quite better than traditional classifier such as logic regression\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
